{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP: SMS Spam Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3A2woqjykhvwXt46SyphR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obrookes/Natural-Language-Processing/blob/master/NLP_SMS_Spam_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu_OR69ADycE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnDAgGx4I4DO",
        "colab_type": "text"
      },
      "source": [
        "**Basics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJOtAZj2JFF1",
        "colab_type": "text"
      },
      "source": [
        "**Text classification: ham or spam**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Akoq1NMJKhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "65f272eb-2ccd-4e95-a6ad-c6e82c98ec90"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY-5esKyOrdz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "86c6ce94-b2d6-4dc0-e5e7-15fd5ed3e5d8"
      },
      "source": [
        "%mkdir nlp\n",
        "%ls \"/content/gdrive/My Drive/nlp\"\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/nlp/spam.csv ./nlp\n",
        "%cd nlp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spam.csv\n",
            "/content/nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAjPTBeJPhnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"spam.csv\", encoding='latin-1').sample(frac=1).drop_duplicates()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cZhQeElRNIM",
        "colab_type": "text"
      },
      "source": [
        "This will remove some duplicates from our dataset, shuffle it (randomise rows) and split the data into train, dev and test sets using the 80/10/10 split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCwQLUO3QJba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[['v1', 'v2']].rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
        " \n",
        "data['label'] = '__label__' + data['label'].astype(str)\n",
        "\n",
        "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
        "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
        "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZZrmYo8SM5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0da8241e-f865-42c3-faac-5e40ccc7bb3c"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ClassificationCorpus\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = './'\n",
        "\n",
        "# load corpus containing training, test and dev data\n",
        "corpus: Corpus = ClassificationCorpus(data_folder,\n",
        "                                      test_file='test.csv',\n",
        "                                      dev_file='dev.csv',\n",
        "                                      train_file='train.csv')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:30:12,552 Reading data from .\n",
            "2020-07-22 16:30:12,555 Train: train.csv\n",
            "2020-07-22 16:30:12,557 Dev: dev.csv\n",
            "2020-07-22 16:30:12,559 Test: test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbUDfrP_U1qm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36b31e02-3647-4ba9-999a-b9b5c1b19ace"
      },
      "source": [
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train('./', max_epochs=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:30:18,793 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpvgndxnxj\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:03<00:00, 5375476.53B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:30:23,583 copying /tmp/tmpvgndxnxj to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:30:23,618 removing temp file /tmp/tmpvgndxnxj\n",
            "2020-07-22 16:30:39,418 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpfutmk02p\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:13<00:00, 1438077.01B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:30:54,232 copying /tmp/tmpfutmk02p to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2020-07-22 16:30:54,265 removing temp file /tmp/tmpfutmk02p\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:30:54,847 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated method __init__. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  \n",
            "100%|██████████| 4652/4652 [00:04<00:00, 1137.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:30:59,219 [b'ham', b'spam']\n",
            "2020-07-22 16:30:59,227 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:30:59,229 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentLSTMEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-07-22 16:30:59,231 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:30:59,233 Corpus: \"Corpus: 4135 train + 517 dev + 517 test sentences\"\n",
            "2020-07-22 16:30:59,234 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:30:59,236 Parameters:\n",
            "2020-07-22 16:30:59,239  - learning_rate: \"0.1\"\n",
            "2020-07-22 16:30:59,241  - mini_batch_size: \"32\"\n",
            "2020-07-22 16:30:59,246  - patience: \"3\"\n",
            "2020-07-22 16:30:59,248  - anneal_factor: \"0.5\"\n",
            "2020-07-22 16:30:59,249  - max_epochs: \"10\"\n",
            "2020-07-22 16:30:59,251  - shuffle: \"True\"\n",
            "2020-07-22 16:30:59,253  - train_with_dev: \"False\"\n",
            "2020-07-22 16:30:59,255  - batch_growth_annealing: \"False\"\n",
            "2020-07-22 16:30:59,256 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:30:59,258 Model training base path: \".\"\n",
            "2020-07-22 16:30:59,261 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:30:59,263 Device: cuda:0\n",
            "2020-07-22 16:30:59,265 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:30:59,267 Embeddings storage mode: cpu\n",
            "2020-07-22 16:30:59,269 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 16:31:06,626 epoch 1 - iter 13/130 - loss 0.33866110 - samples/sec: 61.97\n",
            "2020-07-22 16:31:13,515 epoch 1 - iter 26/130 - loss 0.30361806 - samples/sec: 61.09\n",
            "2020-07-22 16:31:20,399 epoch 1 - iter 39/130 - loss 0.25304065 - samples/sec: 61.10\n",
            "2020-07-22 16:31:26,650 epoch 1 - iter 52/130 - loss 0.22133297 - samples/sec: 72.23\n",
            "2020-07-22 16:31:34,000 epoch 1 - iter 65/130 - loss 0.20811637 - samples/sec: 57.22\n",
            "2020-07-22 16:31:39,822 epoch 1 - iter 78/130 - loss 0.19246973 - samples/sec: 72.42\n",
            "2020-07-22 16:31:45,347 epoch 1 - iter 91/130 - loss 0.17475055 - samples/sec: 76.12\n",
            "2020-07-22 16:31:52,119 epoch 1 - iter 104/130 - loss 0.16299054 - samples/sec: 66.32\n",
            "2020-07-22 16:31:58,785 epoch 1 - iter 117/130 - loss 0.15394092 - samples/sec: 63.18\n",
            "2020-07-22 16:32:03,724 epoch 1 - iter 130/130 - loss 0.14524899 - samples/sec: 85.06\n",
            "2020-07-22 16:32:03,870 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:32:03,872 EPOCH 1 done: loss 0.1452 - lr 0.1000000\n",
            "2020-07-22 16:32:12,433 DEV : loss 0.08764049410820007 - score 0.9857\n",
            "2020-07-22 16:32:12,865 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-07-22 16:32:16,523 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:32:22,672 epoch 2 - iter 13/130 - loss 0.07077328 - samples/sec: 72.31\n",
            "2020-07-22 16:32:28,285 epoch 2 - iter 26/130 - loss 0.07383952 - samples/sec: 75.48\n",
            "2020-07-22 16:32:34,332 epoch 2 - iter 39/130 - loss 0.07458382 - samples/sec: 69.57\n",
            "2020-07-22 16:32:40,241 epoch 2 - iter 52/130 - loss 0.06715178 - samples/sec: 78.06\n",
            "2020-07-22 16:32:45,916 epoch 2 - iter 65/130 - loss 0.07277937 - samples/sec: 74.35\n",
            "2020-07-22 16:32:52,295 epoch 2 - iter 78/130 - loss 0.07335733 - samples/sec: 65.89\n",
            "2020-07-22 16:32:57,763 epoch 2 - iter 91/130 - loss 0.07224433 - samples/sec: 77.05\n",
            "2020-07-22 16:33:04,273 epoch 2 - iter 104/130 - loss 0.07252119 - samples/sec: 64.72\n",
            "2020-07-22 16:33:11,988 epoch 2 - iter 117/130 - loss 0.07194089 - samples/sec: 54.44\n",
            "2020-07-22 16:33:17,734 epoch 2 - iter 130/130 - loss 0.07431412 - samples/sec: 73.13\n",
            "2020-07-22 16:33:17,909 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:33:17,910 EPOCH 2 done: loss 0.0743 - lr 0.1000000\n",
            "2020-07-22 16:33:25,954 DEV : loss 0.22912871837615967 - score 0.9755\n",
            "2020-07-22 16:33:26,353 BAD EPOCHS (no improvement): 1\n",
            "2020-07-22 16:33:26,355 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:33:33,421 epoch 3 - iter 13/130 - loss 0.06665769 - samples/sec: 61.75\n",
            "2020-07-22 16:33:41,093 epoch 3 - iter 26/130 - loss 0.08072706 - samples/sec: 54.92\n",
            "2020-07-22 16:33:46,286 epoch 3 - iter 39/130 - loss 0.07531412 - samples/sec: 80.98\n",
            "2020-07-22 16:33:52,452 epoch 3 - iter 52/130 - loss 0.08130314 - samples/sec: 68.23\n",
            "2020-07-22 16:33:58,302 epoch 3 - iter 65/130 - loss 0.07114032 - samples/sec: 72.14\n",
            "2020-07-22 16:34:04,237 epoch 3 - iter 78/130 - loss 0.08046805 - samples/sec: 71.17\n",
            "2020-07-22 16:34:09,627 epoch 3 - iter 91/130 - loss 0.07901727 - samples/sec: 78.12\n",
            "2020-07-22 16:34:15,639 epoch 3 - iter 104/130 - loss 0.07597150 - samples/sec: 69.95\n",
            "2020-07-22 16:34:21,658 epoch 3 - iter 117/130 - loss 0.07348748 - samples/sec: 70.29\n",
            "2020-07-22 16:34:27,247 epoch 3 - iter 130/130 - loss 0.06878708 - samples/sec: 75.21\n",
            "2020-07-22 16:34:27,430 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:34:27,431 EPOCH 3 done: loss 0.0688 - lr 0.1000000\n",
            "2020-07-22 16:34:35,566 DEV : loss 0.10419827699661255 - score 0.9838\n",
            "2020-07-22 16:34:35,978 BAD EPOCHS (no improvement): 2\n",
            "2020-07-22 16:34:35,979 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:34:42,712 epoch 4 - iter 13/130 - loss 0.05448669 - samples/sec: 65.63\n",
            "2020-07-22 16:34:48,663 epoch 4 - iter 26/130 - loss 0.06462336 - samples/sec: 70.69\n",
            "2020-07-22 16:34:54,890 epoch 4 - iter 39/130 - loss 0.05481170 - samples/sec: 74.97\n",
            "2020-07-22 16:35:00,412 epoch 4 - iter 52/130 - loss 0.05141226 - samples/sec: 76.34\n",
            "2020-07-22 16:35:06,486 epoch 4 - iter 65/130 - loss 0.05085541 - samples/sec: 69.26\n",
            "2020-07-22 16:35:13,258 epoch 4 - iter 78/130 - loss 0.05066573 - samples/sec: 62.03\n",
            "2020-07-22 16:35:19,486 epoch 4 - iter 91/130 - loss 0.05619409 - samples/sec: 67.47\n",
            "2020-07-22 16:35:25,615 epoch 4 - iter 104/130 - loss 0.05387081 - samples/sec: 68.95\n",
            "2020-07-22 16:35:31,284 epoch 4 - iter 117/130 - loss 0.05395282 - samples/sec: 74.34\n",
            "2020-07-22 16:35:36,713 epoch 4 - iter 130/130 - loss 0.05538795 - samples/sec: 77.43\n",
            "2020-07-22 16:35:36,892 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:35:36,893 EPOCH 4 done: loss 0.0554 - lr 0.1000000\n",
            "2020-07-22 16:35:45,626 DEV : loss 0.19496899843215942 - score 0.9691\n",
            "2020-07-22 16:35:46,043 BAD EPOCHS (no improvement): 3\n",
            "2020-07-22 16:35:46,044 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:35:52,789 epoch 5 - iter 13/130 - loss 0.09652631 - samples/sec: 66.40\n",
            "2020-07-22 16:35:58,001 epoch 5 - iter 26/130 - loss 0.07864032 - samples/sec: 80.89\n",
            "2020-07-22 16:36:04,413 epoch 5 - iter 39/130 - loss 0.07146720 - samples/sec: 65.95\n",
            "2020-07-22 16:36:10,012 epoch 5 - iter 52/130 - loss 0.06453710 - samples/sec: 83.78\n",
            "2020-07-22 16:36:15,701 epoch 5 - iter 65/130 - loss 0.05711686 - samples/sec: 74.10\n",
            "2020-07-22 16:36:22,029 epoch 5 - iter 78/130 - loss 0.05114706 - samples/sec: 66.43\n",
            "2020-07-22 16:36:28,001 epoch 5 - iter 91/130 - loss 0.05208260 - samples/sec: 70.40\n",
            "2020-07-22 16:36:33,990 epoch 5 - iter 104/130 - loss 0.04910983 - samples/sec: 76.72\n",
            "2020-07-22 16:36:39,637 epoch 5 - iter 117/130 - loss 0.05386180 - samples/sec: 74.27\n",
            "2020-07-22 16:36:45,806 epoch 5 - iter 130/130 - loss 0.05346320 - samples/sec: 68.18\n",
            "2020-07-22 16:36:45,981 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:36:45,982 EPOCH 5 done: loss 0.0535 - lr 0.1000000\n",
            "2020-07-22 16:36:54,088 DEV : loss 0.051648594439029694 - score 0.9904\n",
            "2020-07-22 16:36:54,505 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-07-22 16:36:58,125 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:37:05,506 epoch 6 - iter 13/130 - loss 0.03236699 - samples/sec: 59.88\n",
            "2020-07-22 16:37:10,766 epoch 6 - iter 26/130 - loss 0.04677949 - samples/sec: 80.17\n",
            "2020-07-22 16:37:16,689 epoch 6 - iter 39/130 - loss 0.04054911 - samples/sec: 70.91\n",
            "2020-07-22 16:37:22,000 epoch 6 - iter 52/130 - loss 0.04401934 - samples/sec: 79.77\n",
            "2020-07-22 16:37:28,994 epoch 6 - iter 65/130 - loss 0.04162327 - samples/sec: 64.49\n",
            "2020-07-22 16:37:35,031 epoch 6 - iter 78/130 - loss 0.04170505 - samples/sec: 69.81\n",
            "2020-07-22 16:37:40,351 epoch 6 - iter 91/130 - loss 0.03824852 - samples/sec: 79.06\n",
            "2020-07-22 16:37:45,895 epoch 6 - iter 104/130 - loss 0.03999476 - samples/sec: 75.93\n",
            "2020-07-22 16:37:52,576 epoch 6 - iter 117/130 - loss 0.04260587 - samples/sec: 67.99\n",
            "2020-07-22 16:37:59,150 epoch 6 - iter 130/130 - loss 0.04608076 - samples/sec: 63.75\n",
            "2020-07-22 16:37:59,317 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:37:59,318 EPOCH 6 done: loss 0.0461 - lr 0.1000000\n",
            "2020-07-22 16:38:07,390 DEV : loss 0.054545219987630844 - score 0.9923\n",
            "2020-07-22 16:38:07,793 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-07-22 16:38:11,362 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:38:16,893 epoch 7 - iter 13/130 - loss 0.02953246 - samples/sec: 80.41\n",
            "2020-07-22 16:38:23,570 epoch 7 - iter 26/130 - loss 0.03445556 - samples/sec: 69.32\n",
            "2020-07-22 16:38:29,551 epoch 7 - iter 39/130 - loss 0.03954417 - samples/sec: 70.36\n",
            "2020-07-22 16:38:35,192 epoch 7 - iter 52/130 - loss 0.03381490 - samples/sec: 74.83\n",
            "2020-07-22 16:38:41,418 epoch 7 - iter 65/130 - loss 0.03382176 - samples/sec: 67.40\n",
            "2020-07-22 16:38:47,110 epoch 7 - iter 78/130 - loss 0.03351311 - samples/sec: 80.80\n",
            "2020-07-22 16:38:53,478 epoch 7 - iter 91/130 - loss 0.03366976 - samples/sec: 66.21\n",
            "2020-07-22 16:38:59,259 epoch 7 - iter 104/130 - loss 0.03533645 - samples/sec: 72.67\n",
            "2020-07-22 16:39:06,087 epoch 7 - iter 117/130 - loss 0.03625331 - samples/sec: 61.84\n",
            "2020-07-22 16:39:12,158 epoch 7 - iter 130/130 - loss 0.03993450 - samples/sec: 69.16\n",
            "2020-07-22 16:39:12,330 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:39:12,331 EPOCH 7 done: loss 0.0399 - lr 0.1000000\n",
            "2020-07-22 16:39:20,526 DEV : loss 0.05132061243057251 - score 0.9914\n",
            "2020-07-22 16:39:20,947 BAD EPOCHS (no improvement): 1\n",
            "2020-07-22 16:39:20,949 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:39:27,176 epoch 8 - iter 13/130 - loss 0.02791686 - samples/sec: 70.67\n",
            "2020-07-22 16:39:32,181 epoch 8 - iter 26/130 - loss 0.06488822 - samples/sec: 84.68\n",
            "2020-07-22 16:39:38,136 epoch 8 - iter 39/130 - loss 0.06902317 - samples/sec: 70.64\n",
            "2020-07-22 16:39:45,837 epoch 8 - iter 52/130 - loss 0.05689606 - samples/sec: 54.45\n",
            "2020-07-22 16:39:51,863 epoch 8 - iter 65/130 - loss 0.05436629 - samples/sec: 70.02\n",
            "2020-07-22 16:39:58,034 epoch 8 - iter 78/130 - loss 0.04880953 - samples/sec: 68.28\n",
            "2020-07-22 16:40:05,870 epoch 8 - iter 91/130 - loss 0.04556218 - samples/sec: 53.68\n",
            "2020-07-22 16:40:11,096 epoch 8 - iter 104/130 - loss 0.04436859 - samples/sec: 80.64\n",
            "2020-07-22 16:40:16,940 epoch 8 - iter 117/130 - loss 0.04271004 - samples/sec: 72.20\n",
            "2020-07-22 16:40:22,153 epoch 8 - iter 130/130 - loss 0.04312741 - samples/sec: 80.67\n",
            "2020-07-22 16:40:22,336 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:40:22,337 EPOCH 8 done: loss 0.0431 - lr 0.1000000\n",
            "2020-07-22 16:40:30,924 DEV : loss 0.1713988482952118 - score 0.981\n",
            "2020-07-22 16:40:31,321 BAD EPOCHS (no improvement): 2\n",
            "2020-07-22 16:40:31,323 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:40:38,953 epoch 9 - iter 13/130 - loss 0.05404604 - samples/sec: 58.02\n",
            "2020-07-22 16:40:44,167 epoch 9 - iter 26/130 - loss 0.03383871 - samples/sec: 81.17\n",
            "2020-07-22 16:40:49,690 epoch 9 - iter 39/130 - loss 0.04738677 - samples/sec: 76.35\n",
            "2020-07-22 16:40:56,976 epoch 9 - iter 52/130 - loss 0.04689119 - samples/sec: 57.74\n",
            "2020-07-22 16:41:02,774 epoch 9 - iter 65/130 - loss 0.04575116 - samples/sec: 72.81\n",
            "2020-07-22 16:41:08,043 epoch 9 - iter 78/130 - loss 0.04312386 - samples/sec: 79.93\n",
            "2020-07-22 16:41:13,749 epoch 9 - iter 91/130 - loss 0.03751927 - samples/sec: 74.01\n",
            "2020-07-22 16:41:19,858 epoch 9 - iter 104/130 - loss 0.03762087 - samples/sec: 68.88\n",
            "2020-07-22 16:41:25,904 epoch 9 - iter 117/130 - loss 0.03926327 - samples/sec: 69.57\n",
            "2020-07-22 16:41:32,363 epoch 9 - iter 130/130 - loss 0.03754920 - samples/sec: 65.11\n",
            "2020-07-22 16:41:32,539 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:41:32,540 EPOCH 9 done: loss 0.0375 - lr 0.1000000\n",
            "2020-07-22 16:41:40,682 DEV : loss 0.05603422224521637 - score 0.9914\n",
            "2020-07-22 16:41:41,089 BAD EPOCHS (no improvement): 3\n",
            "2020-07-22 16:41:41,091 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:41:48,824 epoch 10 - iter 13/130 - loss 0.02366003 - samples/sec: 62.66\n",
            "2020-07-22 16:41:54,158 epoch 10 - iter 26/130 - loss 0.02310307 - samples/sec: 78.92\n",
            "2020-07-22 16:42:00,345 epoch 10 - iter 39/130 - loss 0.02035044 - samples/sec: 68.11\n",
            "2020-07-22 16:42:05,572 epoch 10 - iter 52/130 - loss 0.02512465 - samples/sec: 80.72\n",
            "2020-07-22 16:42:11,263 epoch 10 - iter 65/130 - loss 0.02751785 - samples/sec: 74.17\n",
            "2020-07-22 16:42:16,632 epoch 10 - iter 78/130 - loss 0.03202632 - samples/sec: 78.43\n",
            "2020-07-22 16:42:23,252 epoch 10 - iter 91/130 - loss 0.03037083 - samples/sec: 63.63\n",
            "2020-07-22 16:42:29,358 epoch 10 - iter 104/130 - loss 0.03284140 - samples/sec: 68.80\n",
            "2020-07-22 16:42:35,200 epoch 10 - iter 117/130 - loss 0.03312994 - samples/sec: 78.25\n",
            "2020-07-22 16:42:42,308 epoch 10 - iter 130/130 - loss 0.03594464 - samples/sec: 59.12\n",
            "2020-07-22 16:42:42,475 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:42:42,476 EPOCH 10 done: loss 0.0359 - lr 0.1000000\n",
            "2020-07-22 16:42:50,491 DEV : loss 0.06960493326187134 - score 0.9923\n",
            "Epoch    10: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-07-22 16:42:50,924 BAD EPOCHS (no improvement): 4\n",
            "2020-07-22 16:42:54,412 ----------------------------------------------------------------------------------------------------\n",
            "2020-07-22 16:42:54,413 Testing using best model ...\n",
            "2020-07-22 16:42:54,414 loading file best-model.pt\n",
            "2020-07-22 16:43:02,403 \t0.9826\n",
            "2020-07-22 16:43:02,404 \n",
            "Results:\n",
            "- F-score (micro) 0.9914\n",
            "- F-score (macro) 0.9775\n",
            "- Accuracy 0.9826\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham     1.0000    0.9933    0.9967       451\n",
            "        spam     1.0000    0.9200    0.9583        75\n",
            "\n",
            "   micro avg     1.0000    0.9829    0.9914       526\n",
            "   macro avg     1.0000    0.9567    0.9775       526\n",
            "weighted avg     1.0000    0.9829    0.9912       526\n",
            " samples avg     1.0000    0.9913    0.9942       526\n",
            "\n",
            "2020-07-22 16:43:02,412 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.08764049410820007,\n",
              "  0.22912871837615967,\n",
              "  0.10419827699661255,\n",
              "  0.19496899843215942,\n",
              "  0.051648594439029694,\n",
              "  0.054545219987630844,\n",
              "  0.05132061243057251,\n",
              "  0.1713988482952118,\n",
              "  0.05603422224521637,\n",
              "  0.06960493326187134],\n",
              " 'dev_score_history': [0.9857,\n",
              "  0.9755,\n",
              "  0.9838,\n",
              "  0.9691,\n",
              "  0.9904,\n",
              "  0.9923,\n",
              "  0.9914,\n",
              "  0.981,\n",
              "  0.9914,\n",
              "  0.9923],\n",
              " 'test_score': 0.9914,\n",
              " 'train_loss_history': [0.14524899281812115,\n",
              "  0.07431411712154491,\n",
              "  0.06878707946833366,\n",
              "  0.05538795283780648,\n",
              "  0.053463201580318406,\n",
              "  0.04608076030675035,\n",
              "  0.03993450147637095,\n",
              "  0.043127408150870065,\n",
              "  0.03754919711858607,\n",
              "  0.03594464436397315]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUpOchJOacfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "f9b0818e-60cd-4711-d690-245baa8887d8"
      },
      "source": [
        "classifier = TextClassifier.load('./best-model.pt')\n",
        "\n",
        "# create example sentence\n",
        "sentence = Sentence('click here for free stuff...')\n",
        "\n",
        "# predict class and print\n",
        "classifier.predict(sentence)\n",
        "\n",
        "print(sentence.labels)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-22 17:00:39,882 loading file ./best-model.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0e5252a8a115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./best-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# create example sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, sentences, out_path, embedding_storage_mode, mini_batch_size, num_workers)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mbatch_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mbatch_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/flair/datasets/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'ClassificationCorpus' has no len()"
          ]
        }
      ]
    }
  ]
}